---
title: "Параллелизация и векторизация вычислений"
author: "Vlad"
output:
  html_document: default
  html_notebook: default
  pdf_document: default
---

## Векторизация 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
test1 <- read_delim("~/Downloads/test1.csv", 
    "\t", escape_double = FALSE, col_names = FALSE, 
    col_types = cols(X1 = col_character()), 
    trim_ws = TRUE)[1:1000000,]
```

apply: Поэлементно применяет указанную функцию по указанной оси.
```{r}
#apply a function to each subset of data frame (list)
system.time(
  test1$date <- sapply(test1$X1, function(x){
  return(strsplit(x, " ")[[1]][1])
})
)
tail(test1[, c(1,8)], 10)
```

### DT
```{r}
library(data.table)
grpsize = ceiling(1e7/26^2)
DF <- data.frame(
   x=rep(LETTERS,each=26*grpsize),
   y=rep(letters,each=grpsize),
   v=runif(grpsize*26^2),
   stringsAsFactors=FALSE)
dim(DF)
system.time(ans1 <- DF[DF$x=="R" & DF$y=="h",])
DT = as.data.table(DF)
setkey(DT,x,y)
system.time(ans2 <- DT[list("R","h")])

```

When we used x=="R" we scanned the entire column x, testing each and every value to see if it equalled "R".  We did it again in the y column, testing for "h".  Then &
combined the two logical results to create a single logical vector which was passed to the [ method, which in turn searched it for TRUE and returned those rows.  These were
vectorized operations.  They occurred internally in R and were very fast, but they were scans. We did those scans because we wrote that R code.

tapply: агрегирует и выполняет некие функции.
```{r}
system.time(
  aggreagted <- tapply(X = test1$X7, 
                       INDEX = test1$date,
                       FUN = sum)
  )
tail(aggreagted, 10)
```

Сравним со встроенной функцией. Немного быстрее
```{r}
system.time(
  aggreagted <- aggregate(X7 ~ date,
                          data=test1, FUN=sum)
)
tail(aggreagted, 10)
```

# Параллелизация

#snow
Overview:
 Good for use on traditional clusters, especially if MPI is available. It supports MPI, PVM, nws, and sockets for communication, and is quite portable, running on Linux, Mac OS X, and Windows.
Solves:
 Single-threaded, memory-bound.
Pros:
 Mature, popular package; leverages MPI’s speed without its complexity.
Cons:
 Can be difficult to configure.
#multicore
Overview:
 Good for big-CPU problems when setting up a Hadoop cluster is too much
of a hassle. Lets you parallelize your R code without ever leaving the R interpreter.
Solves:
 Single-threaded.
Pros:
 Simple and efficient; easy to install; no configuration needed.
Cons:
 Can only use one machine; doesn’t support Windows; no built-in support for
parallel random number generation (RNG).
#parallel
Overview:
 A merger of snow and multicore that comes built into R as of R 2.14.0.
Solves:
 Single-threaded, memory-bound.
Pros:
  No  installation  necessary;  has  great  support  for  parallel  random  number
generation.
Cons:
 Can only use one machine on Windows; can be difficult to configure on multiple
Linux machines.

## snow
Исползует SOCK по умолчанию.
```{r}
library(snow)
library(parallel)

  cl <- makeCluster(4)
#apply a function to each subset of data frame (list)
system.time(
  test1$date <- mclapply(test1$X1, FUN = function(x){
  return(strsplit(x, " ")[[1]][1])
})
)
stopCluster(cl)
tail(test1[, c(1,8)], 10)
```

###foreach
C параллелизацией
```{r}
library(snow)
library(foreach)

  cl <- makeCluster(4)
  
system.time(
  temp_set <- foreach(i=1:nrow(test1[1:100000, ]), .combine=rbind) %dopar% test1[i,7]/5
  )

stopCluster(cl)
```
И без:
```{r}
system.time(
  temp_set <- foreach(i=1:nrow(test1[1:100000, ]), .combine=rbind) %do% test1[i,7]/5
  )
```

### plyr, dplyr
```{r, message=FALSE}
library(plyr)
cl <- makeCluster(4)
test1$date <- as.Date(as.character(test1$date))
#apply a function to each subset of data frame
system.time(
  summary <- ddply(test1,
                    .(date),
                    sum = sum(X7),
                    .parallel = TRUE)
)

stopCluster(cl)
```


###h2o
```{r}
library(h2o)
#localH2O = h2o.init()
h2o.init(nthreads = -1)
demo(package = "h2o")
demo(h2o.glm)

h2o.ddply(air2008.filt, "DayOfWeek", fun)
```


###SparkR, Big R (IBM), Microsoft R, R+Hadoop (RHIPE, Segue)

#Интересные сайты
http://stackoverflow.com
http://www.h2o.ai/h2o/h2o-on-r/
http://www.numbertheory.nl
http://www.uio.no/english/services/it/research/hpc/courses/r/2013-04_parallel_r.pdf
#Подробная книга по параллельному R
http://detritus.fundacioace.com/pub/books/Oreilly.Parallel.R.Oct.2011.pdf

#A very, very brief introduction to clustering
http://www.tldp.org/HOWTO/openMosix-HOWTO/x135.html

#Курс по синтаксису Rserver
https://www.datacamp.com/courses/big-data-revolution-r-enterprise-tutorial



